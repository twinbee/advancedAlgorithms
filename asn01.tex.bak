%% Assignment #1 for sorting in linear time

\documentclass[10pt,fullpage]{article}

\usepackage{amsmath,amssymb,amsthm,amsfonts} % Typical maths resource packages

\usepackage{graphics}                 % Packages to allow inclusion of graphics
\usepackage{graphicx}

\usepackage{hyperref}                 % For creating hyperlinks in cross references

\usepackage{listings}

\topmargin -1.5cm \oddsidemargin -0.04cm \evensidemargin -0.04cm
\textwidth 16.00cm \textheight 23.50cm
\parskip 7.2pt
\parindent 0.25in

\makeindex

\title{ Advanced Algorithms Assignment I }

\author{Matthew Bennett \\
{\small\em \copyright \  Draft date \today }}

 \date{ }

\begin{document}
\maketitle

\textbf{Exercise 8.1-1 What is the smallest possible depth of a
leaf in a decision tree for a comparison sort?}

We know already that the height of the decision tree must be $h =
 \Omega(n \lg n)$. That also represents the worst-case. It should be
 clear that $h = \Theta(n \lg n)$ as well, namely within a constant
of 1 (the best case), since the deepest leaf in a complete binary
tree should not differ from the depth of the shortest leaf by more
than 1. Therefore, the minimum number of comparisons for any
comparison sort is $n \lg n - 1$.
\newpage
\textbf{Exercise 8.2-1 Using Figure 8.2 as a model, illustrate the
operation of COUNTING-SORT on the vector A = $\left< 6, 0, 2, 0,
1, 3, 4, 6, 1, 3, 2 \right> $}

A \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  6 & 0 & 2 & 0 & 1 & 3 & 4 & 6 & 1 & 3 & 2 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 2 & 2 & 2 & 1 & 0 & 2 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 4 & 6 & 8 & 9 & 9 & 11 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   &   &   &   &   & 2 &   &   &   &   \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 4 & 5 & 8 & 9 & 9 & 11 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   &   &   &   & 2 &   & 3 &  & &   \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 4 & 5 & 7 & 9 & 9 & 11 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   &   & 1 &   & 2 &   & 3 &   & & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 3 & 5 & 7 & 9 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   &   & 1 &   & 2 &   & 3 & 4 &  & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 3 & 5 & 7 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   &   & 1 &   & 2 & 3 & 3 & 4 &  & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 3 & 5 & 6 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  &   & 1 & 1 &   & 2 & 3 & 3 & 4 &  & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  2 & 2 & 5 & 6 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  0 & 1 & 1 &   & 2 & 3 & 3 & 4 &  &  & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  1 & 2 & 5 & 6 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  0 & 1 & 1 & 2 & 2 & 3 & 3 & 4 & &  & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  1 & 2 & 4 & 6 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  0 & 0 & 1 & 1 & 2 & 2 & 3 & 3 & 4 & & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  0 & 2 & 4 & 6 & 8 & 9 & 10 \\
  \hline
\end{tabular}

B \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
  0 & 0 & 1 & 1 & 2 & 2 & 3 & 3 & 4 & 6 & 6 \\
  \hline
\end{tabular}

C \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
  0 & 2 & 4 & 6 & 8 & 9 & 9 \\
  \hline
\end{tabular}
\newpage
\textbf{Exercises 8.2-2 Prove that COUNTING-SORT is stable.}\\

\begin{verbatim}
 1  for i = 0 to k
 2     do C[i] = 0
 3  for j = 1 to length[A]
 4     do C[A[j]] = C[A[j]] + 1
 5  // C[i] now contains the number of elements equal to i.
 6  for i = 1 to k
 7     do C[i] ? C[i] + C[i - 1]
 8  // C[i] now contains the number of elements less than or equal to i.
\end{verbatim}

Lemma 1: $\forall i, C[i]$ contains the number of elements less
than or equal to i, and must therefore be in increasing order.

This should be apparent from the code lines 1-8, and will not be
proved.

\begin{verbatim}
 9  for j = length[A] downto 1
10     do B[C[A[j]]] = A[j]
11        C[A[j]] = C[A[j]] - 1
\end{verbatim}

\textsc{Loop invariant:} For the loop starting at line 09, at each
execution of the loop, any element A[j] to be placed in the
resultant vector B shall be placed only to the left of any
identical-valued element A[j + $\gamma$] which has already been placed.\\
\textbf{Initialization:} No elements have yet been placed when A[n]
is considered, so the loop invariant holds.\\
\textbf{Maintenance:} Assume that on the j iteration, A[j +
$\gamma$ ] = $\alpha$ is not the first $\alpha$-valued element to
be placed. Then, it will be true that B[C[A[j]]] is assigned
$\alpha$. We know that this $\alpha$ will not be placed in any of
C[A[j + $\gamma$]] = C[$\alpha$], C[$\alpha$ + 1], C[$\alpha$ +
2], $\ldots$ because of the decrementing action on line 11. The
$\alpha$ of iteration j must be placed left of the alpha in the
previous iteration, j + $\gamma$. Specifically, at the next
available left position.\\
\textbf{Termination:}  Assume that on the j iteration, A[j +
$\gamma$ ] = $\alpha$ is not the first $\alpha$-valued element to
be placed. Then, it will be true that B[C[A[j]]] is assigned
$\alpha$. We know that this $\alpha$ will not be placed in any of
C[A[j + $\gamma$]] = C[$\alpha$], C[$\alpha$ + 1], C[$\alpha$ +
2], $\ldots$ because of the decrementing action on line 11. The
$\alpha$ of iteration j must be placed left of the alpha in the
previous iteration, j + $\gamma$. Specifically, at the only left
position.\\

\newpage
\textbf{Exercises 8.3-1 Using Figure 8.3 as a model, illustrate
the operation of RADIX-SORT on the following list of English
words: COW, DOG, SEA, RUG, ROW, MOB, BOX, TAB, BAR, EAR, TAR, DIG,
BIG, TEA, NOW, FOX}

TIME $\longrightarrow$\\
\begin{tabular}{|c|c|c|c|}
  \hline
  COW & SEA & TAB & BAR \\
  DOG & TEA & BAR & BIG \\
  SEA & MOB & EAR & BOX \\
  RUG & TAB & TAR & COW \\
  ROW & DOG & SEA & DIG \\
  MOB & RUG & TEA & DOG \\
  BOX & DIG & DIG & EAR \\
  TAB & BIG & BIG & FOX \\
  BAR & BAR & MOB & MOB \\
  EAR & EAR & DOG & NOW \\
  TAR & TAR & COW & TAB \\
  DIG & COW & ROW & TAR \\
  BIG & ROW & NOW & ROW \\
  TEA & NOW & BOX & RUG \\
  NOW & BOX & FOX & TAR \\
  FOX & FOX & RUG & TEA \\
  \hline
\end{tabular}

 $\bigotimes$

\newpage
\textbf{Exercise 8.3-2 Which of the following sorting algorithms
are stable: insertion sort, merge sort, heapsort, and quicksort?}

Insertion sort is stable, because we iterate through the result
vector A[1..k] until we find a place to "insert" each element
$\alpha$. The condition for insertion is that if $\alpha$ is to be
placed in position A[j], then $A[j-1] \leq \alpha$ and $A[j+1] >
\alpha$, so the original ordering is preserved.

Merge sort is stable. When two elements have the same key, the
LEFT subarray has precedence over the the right subarray, which
maintains the original ordering.

Heapsort is not stable because the max-heapify or min-heapify
property disregards any other ordering which is present.

Quicksort is not stable in general, because the partitioning
scheme may not be stable. However, versions of quicksort may be
stable if they resort to some other stable sort, such as insertion
sort, for partitioning. From wikipedia, "Typically, in-place
partitions are unstable, while not-in-place partitions are
stable."

\textbf{Give a simple scheme that makes any sorting algorithm
stable. How much additional time and space does your scheme
entail?}

One way to assure stable sorting is to make each element a tuple,
with the sorting key as the primary key, but also carry along the
original index as a secondary key, which will be unique. In this
case, sort by comparison on the primary key unless the primary
keys are the same. If that is the case, sort on the secondary
keys.\\

This method requires an extra binary number per element, size $\lg
n$ since the original position must be stored. The space
complexity undergoes $O(n \times sizeof(datatype)) = O(n)
\longrightarrow O(n \lg n)$. This method also requires an extra
comparison per element (worst case). The time complexity undergoes
no transformation: $O(c f(n)) = O(f(n))$.


\end{document}
